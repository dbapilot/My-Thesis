%\chapter{Introduction and Motivation}
\section{Introduction}
\subsection{Motivation}
The motivation for this thesis is driven by the urgent need to enhance query performance in database systems, which are at the heart of many enterprise-level and cloud-based applications. SQL queries are essential for data manipulation and analysis, but they can also be a source of frustration and inefficiency if they are not optimized properly. Despite significant advancements in database technologies, enterprises still face issues such as high latency, poor load balancing, and inefficient data retrieval mechanisms, especially under complex query loads. Addressing these challenges not only improves the user experience but also boosts the overall efficiency of data-driven decision-making processes.\vspace{.4cm}

The collaboration with opta data Gruppe, a company that leverages over 50 years of experience in the healthcare sector to provide tailored digital, financial, and operational solutions for health providers and organizations, provides a unique opportunity to tackle these challenges in a real-world context. Opta data Gruppe has extensive expertise in managing large-scale databases and offers valuable insights and access to proprietary datasets and infrastructure. This partnership will enable the practical application of theoretical concepts and the evaluation of proposed optimizations in a living environment, ensuring that the research outcomes are both scientifically robust and industrially relevant. \vspace{.4cm}

By leveraging opta data Gruppe resources and industry experience, this thesis aims to develop a deep understanding of the limitations present in current query optimization strategies used in database systems. Design and test innovative approaches (a sophisticated algorithm solution) capable of overcoming the prevalent hurdles of databases. We aim to significantly improve search capabilities, which involve the fusion of selection, crossover, and mutation operators from the PSO algorithm to formulate decisions that can swiftly deduce the most efficient execution plans for the queries that can predict and adapt to changing data patterns and query demands in real-time. Measure the impacts of these optimizations on query performance, including reduced latency and increased throughput, in an operational setting.

%%Recognizing the limitations of traditional query optimizers in distributed settings, this research is driven by the ambition to develop a sophisticated algorithmic solution capable of overcoming the prevalent hurdles of distributed databases. By proposing a unique optimizer architecture and deploying the Iterative Dichotomizer 3 (ID3) algorithm as a query optimizer, we aim to significantly improve search capability. This involves the fusion of selection, crossover, and mutation operators from genetic algorithms to formulate decision trees, which can swiftly deduce the most efficient execution plans for queries.

%Moreover, the thesis aims to innovate beyond conventional methods by introducing a caching strategy that mitigates the time cost associated with processing numerous queries. Through rigorous testing and comparative experiments, the research evaluates the execution costs and convergence speeds of Top-k query plans, highlighting the effectiveness of the proposed solutions in achieving superior query efficiency, albeit with a trade-off in execution time.

%The thesis also ventures into the realm of artificial intelligence by presenting "Neo" (Neural Optimizer), a groundbreaking learning-based query optimizer that capitalizes on deep neural networks. This innovative approach to generating query execution plans represents a leap forward in query optimization, underscoring the transformative potential of machine learning in the field of database management.






\subsection{Problem Statement}
The idea of using materialized views for the benefit of improved query processing has been proposed in the literature for more than a decade \cite{Blakeley1986EfficientlyUM}. The presence of the right materialized views can significantly improve performance, particularly for decision support applications. However, to realize this potential, a reasonable selection of materialized views is crucial \cite{agrawal2000automated}. \vspace{.4cm}

A database management system(DBMS) is a crucial software component that enables efficient creation, updating, deleting, and retrieving of data stored in databases. In the era of big data, databases have become a cornerstone for handling vast amounts of information across multiple locations. As the backbone of large-scale online applications, such as social media platforms, e-commerce sites, and cloud services, the ability of these systems to efficiently process queries is paramount. The performance of databases directly influences the responsiveness of applications and, by extension, user experience and business operations.\cite{4} Especially in database systems, one of the most important factors related to large databases is query optimization and response time, on-time access to information, and it is the basic requirement of successful business applications. A data warehouse implements many materialized views to process a predefined set of queries with speed efficiently. For any database, quick response time and accuracy are very important factors in considering its success \cite{karde2010selection}.\vspace{.4cm} 

A necessary condition for the success of a data warehouse is to provide accurate and timely consolidated information for the decision-makers, along with fast query response times. For this purpose, a common method used in practice is the use of higher information and the best concept of response time, whereby a query gets answered quickly. One of the most important decisions in designing data Warehouses is selecting views to materialize for the purpose of efficiently supporting the decision-making. The view selection problem is defined as selecting a set of derived views to materialize that minimizes the sum of total query response time and maintains the selected views. Thus, the goal is to select a good set of views that minimizes the overall query response time and also maintains the selected views. The decision "What is the best set of views to materialize?" is to be made based on the system workload, a sequence of queries and updates that exemplifies the typical load on the system. The criterion can be very simple, for example, one that simply minimizes the overall execution time of workload queries.\vspace{.4cm}

In relational databases, a view is a function from a set of based tables to a derived table; the function is recomputed every time the view is referenced. A materialized view, on the other hand, is, so to say, a cache: that is, a duplicate of the data represented that can be accessed fast. Therefore, it is evident that the use of materialized views incorporating not just traditional simple SELECT PROJECT JOIN operators but also complex online analytical processing operators contribute significantly to improving online analytical process (OLAP) query performance. Materialized views are used in data warehousing, replication servers, recording systems, and data visualization and mobile systems. In some cases, it can be more advantageous to materialize the view than to have to compute the base tables each time the view is queried. Each time a change is made to the base tables to which the view refers, the materialized view is refreshed. It can be quite costly to rematerialize this view every time a change may affect one of the base tables. So, it is ideal to propagate the changes incrementally; the materialized view should be refreshed for incremental changes to base tables \cite{Data_warehousing,efficient_incremental,rashid2009role}.\vspace{.4cm}

While the applications of databases are extensive, they present many unique challenges in query performance optimization. Such systems need to handle not only large volumes of data but also data that is spatially dispersed. Such dispersion requires complex coordination and communication among different nodes with inherent latency and potential bottlenecks that can degrade query performance. Moreover, network variability and heterogeneity characteristic features of a database environment further complicate the effective execution of queries.

\subsection{Overview of Opta data Gruppe}
%\normalsize
\subsubsection{Opta data Stiftung \& Co. KG }
Opta data Stiftung \& Co. KG acts as the umbrella organization of the opta data Group, which brings together relevant areas for the entire company. This also includes working Student, trainees, although they work and can be trained in various specialist areas. Opta data Holding is a company that specializes in Billing, IT and services in the healthcare sector.

\subsubsection{Opta data Finance GmbH  }
Opta data Finance GmbH (referred to as odFIN) is part of opta data Holding and is one of the leading companies in the healthcare billing sector. With a wide range of products, odFIN offers various solutions for service providers and payers in the healthcare sector. As an innovator, the company is actively driving digitalization in the healthcare sector and occupies a leading position in the telemetry infrastructure.

\subsubsection{Business Area egeko }
The egeko division at odFIN develops and supports software systems for electronic approval procedures in the healthcare sector. With a focus on electronic cost estimates (eKV), the egeko division offers innovative solutions with the software of the same name for service providers in the medical aid and care sector, among others. The company facilitates processes between service providers and health insurance companies by supporting the entire service provision process.\vspace{.4cm}

The division's software development is made up of a total of three scrum teams and two additional Kanban teams. The scrum teams focus on development with a focus on central services, aids, care, and master data \& patient transport. DevOps and quality assurance provide support.\vspace{.4cm} 

As a part of egeko, team DevOps is a cross-functional group that combines software development (Dev) and IT operations (Ops) roles, aiming to create a more efficient and integrated approach to building, testing, and releasing software. Key characteristics of a DevOps team include automating everything: deployment, infrastructure, test, build, scale, promoting fault tolerance, server monitoring, and static code errors that do not directly reduce software quality from the customer's point of view. However, error prevention blocks the CI/CD pipeline's agile approach. A platform can be migrated anywhere and at any time. Further CIPs are used to make everyday life easier, avoid click tasks, and create mutual trust in each other and in old/new technologies. Active knowledge transfer, definition of consulting measures, support and introducing people to new technologies No fear of new technologies, first evaluate then judge. Create shared visions and responsibility, and realize wishes. A start-to-finish responsibility, everyone is involved can get involved and strengthen collaboration.\vspace{.4cm}

The egeko software is used by third-party customers. To ensure that customer requests are fulfilled and faults are rectified, there is a team responsible for customer support. The customer support team has a ticket database that records messages and faults from customers.\vspace{.4cm}

I have finished my internship in the DevOps team in the egeko division. The DevOps team is part of the development of egeko. I have been assigned the task of continuing the optimization of egeko's database infrastructure, which has given better results for the existing server in Opta Data Finance GmbH. I must do the following Tasks: Monitoring database performance, server health checks, conducting regular performance tuning, and optimizing queries for maximum efficiency. Manage and optimize healthcare databases to ensure the availability and reliability of critical organizational [website] actual and future ETL processes to ensure optimization and best practices. Develop and implement data security policies, procedures, and best practices to protect sensitive healthcare information.\vspace{.4cm}

The area of my key activities included the following tasks:
\begin{itemize}
    \item Optimization of database infrastructure.
    \item Database design, management, planning, and tuning.
    \item Performance analysis, monitoring, and alerting.
    \item Query optimization and maintained security management.
    \item Development and implementation of backup strategies.
    \item Disaster recovery and documentation.
\end{itemize}
\vspace{.4cm}

I used most of Microsoft SQL Server Management Studio (SSMS), VSCode, Grafana (a multi-platform open-source analytics and interactive visualization web application), mRemoteng, and MSSQL as programming languages.

\subsection{Goal of this Thesis}
\normalsize
This thesis conducts a thorough review of the literature on cost estimation (Query performance ) within relational databases, a critical component of the query optimization process. For this systematic review to be effective, precise objectives must be established. These principal aims are outlined in the study \cite{CostEstimation}.
\begin{itemize}
  \item To provide an overview of the materialized view, an efficient query optimizer in databases with the details of the approaches.
  \item To provide a comprehensive and efficient solution.
  \item To find the limitations of the approaches.
  \item To understand the scope for further research which contributes towards building
better query optimizes/Performance \cite{CostEstimation}.
\end{itemize}
\subsection{Structure of the Thesis }
The following sections focus on the objectives of the systematic literature. In section 2, we will provide a background of materialized views on databases. It includes an overview of query processing, query optimization, and cost estimation.\vspace{.4cm}

In Section 3, the Methodology section, we will discuss the systematic approach to investigate and implement materialized views for query optimization in a database system, including the specific steps, tools, and techniques used to demonstrate the effectiveness of materialized views.\vspace{.4cm}

At the end of the thesis, we will discuss limitations and future work related to this topic that can be conducted.]










