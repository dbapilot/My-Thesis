%\chapter{Introduction and Motivation}
\section{Introduction}
This chapter outlines the motivation behind the thesis and objectives of critical issues faced by enterprises surrounding query performance in modern database systems.
\subsection{Motivation}
The motivation for this thesis is driven by the urgent need to enhance query performance in database systems, which are a core part of many enterprise-level and cloud-based applications. SQL queries are essential for data manipulation and analysis, but they can also be a source of irritation and inefficiency if they are not properly optimized. Despite significant advancements in database technologies, enterprises still face issues such as high latency, poor load balancing, and inefficient data retrieval mechanisms, especially under complex query loads. Addressing these challenges not only improves the user experience but also boosts the overall efficiency of data-driven decision-making processes.\vspace{.4cm}

The collaboration with opta data Gruppe, a company that leverages over 50 years of experience in the healthcare sector to provide tailored digital, financial, and operational solutions for health providers and organizations, provides a unique opportunity to tackle these challenges in a real-world context. Opta data Gruppe has extensive expertise in managing large-scale databases and offers valuable insights and access to proprietary datasets and infrastructure. This partnership will enable the practical application of theoretical concepts and the evaluation of proposed optimizations in a living environment, ensuring that the research outcomes are both scientifically robust and industrially relevant. \vspace{.4cm}

This thesis report seeks to investigate how advanced query optimization techniques could enhance database performance and efficiency within the company's operations. Materialized views are an excellent way to improve the efficiency of complex queries by pre-computing and storing frequently used results over existing methods. Unlike traditional query optimization techniques, implementing materialized views might significantly lead to faster query response times, reduced server load, and improved overall system efficiency for our business, particularly in reporting and analytics, where aggregations and joins across large datasets are typical. Furthermore, by proactively selecting and controlling materialized views based on query frequency and complexity, this approach may boost performance, maximize resource utilization, and ensure a more responsive system, resulting in cost savings and increased productivity compared to conventional optimization methods. This strategy could be especially effective for accelerating decision-making procedures that rely on quick access to critical data insights.\vspace{.4cm}

By leveraging opta data Gruppe resources and industry experience, this thesis aims to develop a deep understanding of the limitations present in current query optimization strategies used in database systems. Design and test innovative approaches (a sophisticated algorithm solution) capable of overcoming the prevalent hurdles of databases. It intends to significantly improve search capabilities by combining the PSO algorithm's selection, crossover, and mutation operators to form decisions that quickly determine the most efficient execution plans for queries that can predict and adapt to changing data patterns while remaining relevant and up-to-date without incurring excessive overhead. In an operational environment, investigate the effects of these improvements on query performance, such as decreased latency and increased throughput. \vspace{.4cm}


%%Recognizing the limitations of traditional query optimizers in distributed settings, this research is driven by the ambition to develop a sophisticated algorithmic solution capable of overcoming the prevalent hurdles of distributed databases. By proposing a unique optimizer architecture and deploying the Iterative Dichotomizer 3 (ID3) algorithm as a query optimizer, we aim to significantly improve search capability. This involves the fusion of selection, crossover, and mutation operators from genetic algorithms to formulate decision trees, which can swiftly deduce the most efficient execution plans for queries.

%Moreover, the thesis aims to innovate beyond conventional methods by introducing a caching strategy that mitigates the time cost associated with processing numerous queries. Through rigorous testing and comparative experiments, the research evaluates the execution costs and convergence speeds of Top-k query plans, highlighting the effectiveness of the proposed solutions in achieving superior query efficiency, albeit with a trade-off in execution time.

%The thesis also ventures into the realm of artificial intelligence by presenting "Neo" (Neural Optimizer), a groundbreaking learning-based query optimizer that capitalizes on deep neural networks. This innovative approach to generating query execution plans represents a leap forward in query optimization, underscoring the transformative potential of machine learning in the field of database management.






\subsection{Problem Statement}
The idea of using materialized views for the benefit of improved query processing has been proposed in the literature for more than a decade \cite{Blakeley1986EfficientlyUM}. The presence of the right materialized views can significantly improve performance, particularly for decision support applications. However, to realize this potential, a reasonable selection of materialized views is crucial \cite{agrawal2000automated}.\vspace{.4cm}

Earlier approaches to query optimization encountered several significant challenges that impacted their effectiveness. One of the main issues was scalability; as the number of materialized views grew, the algorithms often struggled to keep up, leading to delays in processing times in large databases. Additionally, maintaining these views became tricky in dynamic environments where data changes frequently, creating a frustrating trade-off between having up-to-date information and achieving optimal performance. The interactions between materialized views and indices were often less than ideal, resulting in inefficiencies and redundant computations that further hampered overall efficiency. These challenges underscored the urgent need for more flexible and integrated optimization strategies that could enhance both practicality and performance in dynamic settings.\vspace{.4cm}

A database management system(DBMS) is a crucial software component that enables efficient creation, updating, deleting, and retrieving of data stored in databases. In the era of big data, databases have become a cornerstone for handling vast amounts of information across multiple locations. As the backbone of large-scale online applications, such as social media platforms, e-commerce sites, and cloud services, the ability of these systems to efficiently process queries is paramount. The performance of databases directly influences the responsiveness of applications and, by extension, user experience and business operations \cite{4}. Especially in database systems, one of the most important factors related to large databases is query optimization and response time, as well as on-time access to information, which are the basic requirements of successful business applications. A data warehouse implements many materialized views to process a predefined set of queries with speed efficiently. For any database, quick response time and accuracy are very important factors in considering its success \cite{karde2010selection}.\vspace{.4cm}

A necessary condition for the success of a data warehouse is to provide accurate and timely consolidated information for the decision-makers, along with fast query response times. For this purpose, a common method used in practice is the use of higher information and the best concept of response time, whereby a query gets answered quickly. One of the most important decisions in designing data Warehouses is selecting views to materialize for the purpose of efficiently supporting the decision-making. The view selection problem is defined as selecting a set of derived views to materialize that minimizes the sum of total query response time and maintains the selected views. Thus, the goal is to select a good set of views that minimizes the overall query response time and also maintains the selected views. The decision ``What is the best set of views to materialize?'' is to be made based on the system workload, a sequence of queries and updates that exemplifies the typical load on the system. The criterion can be very simple, for example, one that simply minimizes the overall execution time of workload queries.\vspace{.4cm}

In relational databases, a view is a function from a set of based tables to a derived table; the function is recomputed every time the view is referenced. A materialized view, on the other hand, acts like a cache: a duplicate of the represented data that can be accessed efficiently. Therefore, it is evident that the use of materialized views incorporating not just traditional simple SELECT PROJECT JOIN operators but also complex online analytical processing operators contribute significantly to improving online analytical process (OLAP) query performance. Materialized views are used in data warehousing, replication servers, recording systems, and data visualization and mobile systems. In some cases, it can be more advantageous to materialize the view than to have to compute the base tables each time the view is queried. Each time a change is made to the base tables to which the view refers, the materialized view is refreshed. It can be quite costly to rematerialize this view every time a change may affect one of the base tables. So, it is ideal to propagate the changes incrementally; the materialized view should be refreshed for incremental changes to base tables \cite{Data_warehousing,efficient_incremental,rashid2009role}.\vspace{.4cm}

Databases serve many purposes, but they present unique challenges in query performance optimization. These systems need to handle not only large volumes of data but also spatially dispersed data. Such dispersion requires complex coordination and communication among different nodes, which can lead to latency and potential bottlenecks that can degrade query performance. Additionally, network variability and the unpredictability common in a database environment further complicate the effective execution of queries.

\subsection{Overview of Opta data Gruppe}
%\normalsize
\subsubsection{Opta data Stiftung \& Co. KG }
Opta data Stiftung \& Co. KG acts as the umbrella organization of the opta data Group, which brings together relevant areas for the entire company. This also includes working Students and trainees, although they work and can be trained in various specialist areas. Opta data Holding is a company that specializes in billing, IT, and healthcare services.

\subsubsection{Opta data Finance GmbH  }
Opta data Finance GmbH (referred to as odFIN) is part of opta data Holding and is one of the leading companies in the healthcare billing sector. With a wide range of products, odFIN offers various solutions for service providers and payers in the healthcare sector. As an innovator, the company is actively driving digitalization in the healthcare sector and occupies a leading position in the telemetry infrastructure.

\subsubsection{Business Area egeko }
The egeko division at odFIN develops and supports software systems for electronic approval procedures in the healthcare sector. With a focus on electronic cost estimates (eKV), the egeko division offers innovative solutions with the software of the same name for service providers in the medical aid and care sector, among others. The company facilitates processes between service providers and health insurance companies by supporting the entire service provision process.\vspace{.4cm}

The division's software development is made up of a total of three scrum teams and two additional Kanban teams. The scrum teams focus on development with a focus on central services, aids, care, and master data and patient transport. DevOps and quality assurance provide support.\vspace{.4cm} 

As a part of egeko, team DevOps is a cross-functional group that combines software development (Dev) and IT operations (Ops) roles, aiming to create a more efficient and integrated approach to building, testing, and releasing software. Key characteristics of a DevOps team include automating everything: deployment, infrastructure, test, build, scale, promoting fault tolerance, server monitoring, and static code errors that do not directly reduce software quality from the customer's point of view. However, error prevention blocks the CI/CD pipeline's agile approach. A platform can be migrated anywhere and at any time. Further, CIPs are used to make everyday life easier, avoid click tasks, and create mutual trust in each other and old or new technologies. Active knowledge transfer, definition of consulting measures, support and introducing people to new technologies No fear of new technologies, first evaluate then judge. Create shared visions and responsibility, and realize wishes. A start-to-finish responsibility, everyone is involved can get involved and strengthen collaboration.\vspace{.4cm}

The egeko software is used by third-party customers. To ensure that customer requests are fulfilled and faults are rectified, there is a team responsible for customer support. The customer support team has a ticket database that records messages and faults from customers.\vspace{.4cm}

I have finished my internship in the DevOps team in the egeko division. The DevOps team is part of the development of egeko. I have been assigned the task of continuing the optimization of egeko's database infrastructure, which has given better results for the existing server in Opta Data Finance GmbH. I must do the following Tasks: Monitoring database performance, server health checks, conducting regular performance tuning, and optimizing queries for maximum efficiency. Manage and optimize healthcare databases to ensure the availability and reliability of critical organizational website actual and future ETL processes to ensure optimization and best practices. Develop and implement data security policies, procedures, and best practices to protect sensitive healthcare information. The area of my key activities included the following tasks:\vspace{.4cm}
\begin{itemize}
    \item Optimization of database infrastructure.
    \item Database design, management, planning, and tuning.
    \item Performance analysis, monitoring, and alerting.
    \item Query optimization and maintained security management.
    \item Development and implementation of backup strategies.
    \item Disaster recovery and documentation.
\end{itemize}

I used most of Microsoft SQL Server Management Studio (SSMS), VSCode, Grafana (a multi-platform open-source analytics and interactive visualization web application), mRemoteng, and MSSQL as programming languages.\vspace{.4cm}

The issues that opta data Gruppe faces in managing healthcare data are closely related to this thesis, as fragmentation of data information across numerous systems makes it difficult to achieve a unified view of records. As the volume of data increases and changes frequently, the time taken to retrieve required information can significantly impact user experience. Users expect quick and up-to-date access to data, and any delays can be frustrating and decrease productivity. Slow response times can cause bottlenecks, blocking other queries and further slowing down overall performance. Optimizing query performance by prioritizing query response time opta data Gruppe directly contributes to improved performance and user satisfaction.

\subsection{Goal of this Thesis}
\normalsize
This thesis conducts a thorough review of the literature on cost estimation (Query performance ) within relational databases, a critical component of the query optimization process. For this systematic review to be effective, precise objectives must be established. These principal aims are outlined in the study \cite{CostEstimation}. The following key points are the goal of this work: 
\begin{itemize}
  \item To provide an overview of the materialized view, an efficient query optimizer in databases with the details of the approaches.
  \item To provide a comprehensive and efficient solution.
  \item To find the limitations of the approaches.
  \item To understand the scope for further research, which contributes towards building
better query Performance. %\cite{CostEstimation}.
\end{itemize}
\subsection{Structure of the Thesis }
The following sections focus on the objectives of the systematic literature. In section 2, we will provide a background of materialized views on databases. It includes an overview of query processing, query optimization, and cost estimation.\vspace{.4cm}

In Section 3, the Methodology section, we will discuss the systematic approach to investigate and implement materialized views for query optimization in a database system, including the specific steps, tools, and techniques used to demonstrate the effectiveness of materialized views.\vspace{.4cm}

At the end of the thesis, we will discuss limitations and future work related to this topic that can be conducted.










