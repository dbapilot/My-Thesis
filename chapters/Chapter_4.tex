%\chapter{Implementaion}

\section{Implementations}
This section describes a step-by-step process for effectively deploying materialized views, and PSO algorithm based on the earlier theoretical foundations, to reduce query execution time, minimize computational overhead, and enhance overall performance. The implementation begins with an overview of the tools and technologies utilized in this project, providing essential context before delving into the optimization process.

\subsection{Used Software and Tools}
This project uses some software tools and technologies related to database management, query optimization, and technical documentation. Collectively, these tools support database management, query optimization, data analysis, and technical documentation throughout the research and development process.

\begin{enumerate}[label=(\roman*)]
\item\textbf{SQL Server Management Studio :} SQL Server Management Studio(SSMS) is actually an integrated environment that can maintain the SQL Server infrastructure. It is used to access, manage, configure, administer, and develop all components of SQL Server. In addition, it is used to manage the schema, tables, access to SQL Server, and materialized views of the database. Also, it monitors the performance of the query using execution plans and statistics, and it helps to debug SQL queries and optimize their execution. Here, MSSQL is used to host the database, create tables, and define materialized views, enabling query execution and performance measurement.


\item\textbf{{Visual Studio Code:}} Microsoft created this open-source integrated development environment (IDE) for web browsers, Linux, macOS, and Windows. It is used to write Python scripts for automation (e.g., measuring query performance), integrate MSSQL queries with Python using extensions, and debug Python and SQL scripts. VS Code is used as the primary Integrated Development Environment (IDE) for writing, debugging, and running Python scripts that implement the PSO algorithm and interact with the SQL Server database.

\item\textbf{Overleaf:} Overleaf is an open-source online, real-time collaborative LaTeX\footnote{LaTeX is a powerful typesetting system commonly used for academic and technical documents. It includes features designed for the production of technical and scientific documentation.} editor that simplifies the process of creating, editing, and collaborating on LaTeX documents. The whole project is written with the help of Overleaf.

\item\textbf{Microsoft SQL Server:} Microsoft SQL Server is a relational database that provides a wide range of features for storing, processing, and securing data. SQL Server hosts the database, stores the tables and materialized views, and executes the SQL queries, allowing the measurement and optimization of query performance using the PSO algorithm.


\item\textbf{Python:} Python is a high-level interpreted programming language known for its simplicity and readability. It was created by Guido van Rossum and released in 1991 \cite{martin2023stam,wijanarko2020prediksi} . It has become one of the most popular programming languages worldwide. Its object-oriented approach helps programmers to write logical and clear code for small and large projects. Python libraries (packages) effectively simplify many important processes such as analyzing and visualizing data, retrieving unstructured data from the web, image processing, building machine learning models, and textual information \cite{Samira_Gholizadeh2022}. Here, it has been used to implement the PSO algorithm to optimize query performance, connect to the database using libraries like pyodbc, measures, executes, and analyzes the database programmatically. Due to its simplicity, readability, extensive libraries, ease of use, and efficiency, it is one of the best choices for implementing PSO.

\item\textbf{pyodbc:} Pyodbc is an open-source Python module that makes accessing ODBC\footnote{Open Database Connectivity (ODBC) is a standardized application programming interface (API) for accessing databases.} databases simple. It implements the DB API\footnote{An Application Programming Interface (API) is a set of protocols, tools, and definitions that allow different software applications to communicate with each other.} 2.0 specification but is packed with even more Pythonic convenience. The pyodbc library connects Python to MSSQL, allowing programmatic execution of SQL queries and retrieval of results.

\item\textbf{pandas:} The pandas constitute an open-source data manipulation and analysis tool that is fast, powerful, flexible, and easy to use. It provides data structures like DataFrames and Series, which are particularly useful for working with structured data. It is built entirely on the Python programming language. Pandas is used to analyze query performance data, such as execution times and storage costs, for better insights.

\item\textbf{matplotlib:} Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python. \enquote{Matplotlib makes easy things easy and hard things possible} \cite{matplotlib}. It has been used to visualize query performance metrics and PSO convergence, making results easier to interpret.

\item\textbf{GitHub:} GitHub is an open-source version control system that is used for tracking the changes made in the files and for enabling a collaborative software world. GitHub is incredibly popular due to its flexibility, speed, and ability to support almost any workflow. It has become the world's largest source code host, with around 90 per cent of developers worldwide using it to create, store, manage, and share their code. GitHub is used to track changes in Python scripts, LaTeX documents, and SQL files, making it an essential tool for collaboration and version control during thesis development. The platform’s features, such as branching, pull requests, and issue tracking, enable efficient project management and seamless integration of feedback from advisors or peers. Additionally, GitHub’s public or private repository options allow me to share my work with the academic community while retaining control over access.

\end{enumerate}

\clearpage

\subsection{Practical Implementation }

\subsubsection{Database Creation}
Choosing a database or creating one if not available is the initial step of the implementation. For the demonstration purpose of this thesis only, one database called \texttt{HealthInsuranceDB} is created here. The database was populated with tables and sample data to simulate a real-world environment. Relationships among tables are created through primary keys and foreign keys to ensure data integrity and efficient querying, enabling the testing and optimization of queries using materialized views and the PSO algorithm.

The following SQL query checks if the database \texttt{HealthInsuranceDB} exists and creates it if it does not: \vspace{.4cm}

\input{SQL/Create_database}


\subsubsection{Table Creation} A database schema with four tables, namely \texttt{InsuranceProviders}, \texttt{Patients}, \texttt{Claims}, and \texttt{Treatments}, are created with the help of the following SQL query. These tables are intended to store information on insurance providers, patient details, insurance claims, and associated treatments respectively. Foreign key constraints ensure data integrity as they set up relationships between the tables, making this schema suitable for demonstrating materialized views and query optimization in a health insurance context. \vspace{.4cm}

\input{SQL/table_creation}
\subsubsection{Inserting Random Data in Database}
One million patient records are automatically generated through a looped SQL script~\ref{lst:inserting_data}. Random values are assigned for date of birth (ranging from 0-100 years), gender (evenly distributed among M/F/O), and location data (address, city, state, and zip code).\vspace{.4cm}

 \input{SQL/inserting_data}

\subsubsection{Identify Complex Queries} This is a very important part of identifying the frequent queries that need to be optimized. It refers to the process of analyzing a database workload to pinpoint queries that are resource-intensive, frequently executed, or critical to performance. SQL Server Management Studio or direct SQL query can be used to analyze execution logs and identify the frequently executed and resource-intensive queries. Also, identify frequently used sub-queries, aggregation (Queries with GROUP BY, SUM, AVG)s, or frequent joins between tables. For example, the following query to identify long-running queries: \vspace{.4cm}

\input{SQL/Query_identify}

As shown in Listing~\ref{lst:IdentifyComplexQueries}, query retrieves the top 10 most time-consuming queries from SQL Server by analyzing the \(\texttt{sys.dm\_exec\_query\_stats}\) Dynamic Management Views(DMV)\footnote{DMVs are system defined views for database administrators and developers to troubleshoot performance issues, identify missing indexes, analyze query performance, and monitor resource usage efficiently.}. It calculates the total elapsed time in milliseconds, counts the number of executions, and fetches the query text using \(\texttt{sys.dm\_exec\_sql\_text}\). The results are sorted by \(\texttt{total\_elapsed\_time}\) in descending order to highlight the slowest queries for performance tuning and optimization. These queries were then used to create materialized views, which were optimized using the PSO algorithm to improve overall query performance.

\subsubsection{ Materialized views Creation (Indexed Views)}\label{Query_decomposition} Once the top slow queries are sorted out, MVs(In MSSQL Server Mvs are implemented as Indexed views ) are created for each of these queries to store their precomputed results.\vspace{.4cm}

  %\input{SQL/Create_MSSQL}
  \input{SQL/Create_Views}\vspace{.4cm} 



These materialized/indexed views in listing ~\ref{lst:MV_creation} are designed to optimize query performance in a health insurance database by precomputing and storing aggregated results. The \texttt{TotalClaimsByPatient} view demonstrates the retrieval of claim counts per patient, while the \texttt{TotalTreatmentCostByProvider} view offers a rapid summary of treatment costs by the insurance provider. The \texttt{MonthlyClaimsByProvider} view breaks down monthly claims in detail, enabling efficient analysis of claim trends over time. By materializing these views with unique clustered indexes, the database ensures faster query execution and reduced computational costs on data with frequent access.



  \subsubsection{View Maintenance and Refresh Strategies}\label{View_maintainance} Incremental, Manual or automatic refresh strategies can be set up according to the requirements query to create a scheduled job with the help of script as in the listing ~\ref{lst:Maintenance_and_Refresh_Strategies}.\vspace{.4cm}

\input{SQL/Refresh_config}\vspace{.4cm}

As the database is created here only for demonstration purposes and all data are inserted once manually, therefore materialized views are refreshed manually. This approach is suitable for scenarios where immediate updates are required or when automated refresh mechanisms (like triggers or scheduled jobs) are not feasible. Manual refresh ensures that the views reflect the latest changes in the underlying data, providing accurate results for query processing.\vspace{.4cm}

\subsection{Automation with the PSO algorithm:} \label{Cost_evaluation}
 The following Python code illustrates the implementation of the PSO algorithm for multiple values in the database system. The goal is to minimize query execution time and CPU cost by selecting the most beneficial views to materialize. This section provides a detailed explanation of each function in the implementation.



%\section*{\textbf{Code example to selecting the optimal view using PSO algorithm.} \vspace{.4cm}}

\input{Python/PSO_python}\vspace{.4cm}

A sequence diagram in figure ~\ref{fig:Sequence_diagram} is included here to help better understand the workflow and interactions between the system's components. It provides a step-by-step visualisation of how this code operates, making it more understandable.
  
 % \input{Python/PSO_Best_Response} \vspace{.4cm}


\clearpage


% Define block styles


% Inserting the image
\begin{figure}[h]
    \centering
    \includegraphics[width=0.5\textwidth]{Figure/seq.diagram .png} % Replace 'example-image' with your image file name
    \caption{Sequence diagram of code}
    \label{fig:Sequence_diagram}
\end{figure}






\subsubsection{Output from PSO automation }  Upon execution for a specified number of iterations, the code records the best combination of materialized views that minimize the total cost. It makes a list of the iteration-wise data, including the best execution time, CPU cost and the corresponding views for each iteration. Finally, it prints the overall best view according to their parameters. Below is the sample of the output from the python code: \vspace{.4cm}



  \input{Python/Python_output} \vspace{.4cm}
  

  %\input{Python/python_output2} \vspace{.4cm}

  

\textbf{For the full code and further test cases, please refer to the Appendix~\ref{fullcode:Fullcode}.}


\subsection{Performance Testing and Data Analysis} After creating the materialized views on the database \texttt{"HealthInsuranceDB"}, performance metrics were collected using SQL query statistics. Query elapsed times and CPU usages are recorded using built-in database monitoring tools, such as Dynamic Management Views (DMVs) or with the help of SQL queries. \vspace{.4cm}

 \input{SQL/Query_statistics}

 \textbf{The full script to analyse performance is provided in listing ~\ref{lst:Analysis}.}

\begin{enumerate}


    \item \textbf{ Query response time comparison:}\\
The tests were performed using \textit{MSSQL} on a system running \textit{Windows 10 Pro} with the following specifications:
\begin{itemize}
    \item \textbf{System Type}: 64-bit operating system, x64-based processor.
    \item \textbf{Processor}: 12th Gen Intel(R) Core(TM) i7-1255U, 1.70 GHz.
    \item \textbf{RAM}: 32 GB.
    \item \textbf{Server}: MSSQL.
\end{itemize}\vspace{.4cm}

After executing each query multiple times, both with and without materialized views, the \textit{response time}\footnote{Time taken to execute queries} and \textit{CPU usage}\footnote{Percentage of CPU utilization during query execution and refresh processes.} were noted in from the "Messages" tab in SSMS. The effectiveness of the materialized views was also evaluated using a comparison table and the percentage difference formula.

\begin{itemize}
\item\textbf{Differences between optimization methods:} The following \hyperref[comparison_table]{\textit{Table}~\ref*{comparison_table}} presents a performance comparison of elapsed time using two different approaches: \textit{Direct SELECT Aggregation}, and \textit{Materialized View}. The results show that the MV approach consistently outperforms the other method, with an average execution time of \textbf{69.2 ms}, compared to \textbf{106.6 ms} for direct \textit{SELECT} aggregation. This demonstrates that materialized views significantly reduce query execution time, providing a \textbf{35.08\%} improvement over direct aggregation. The consistent performance across multiple runs highlights the reliability and efficiency of materialized views in optimizing database queries.\vspace{.4cm}
 
 \input{Table/Response_time_comparion}\vspace{.4cm
 }

 \item\textbf{Analysis of percentage differences in query performance:}
 
\input{Math/Differences}

\begin{comment}\[
\text{Difference (\%)} = \frac{\text{Without MV} - \text{With MV}}{\text{Without MV}} \times 100 = \frac{2.35 - 0.45}{2.35} \times 100 \approx 80.85\%
\]
\end{comment}\vspace{.4cm}

The output indicates an \textit{39.47\% }improvement in performance. Here, \( W = 114 \) represents the initial execution time (without optimization), and \( M = 69 \) represents the improved execution time (with optimization). This significant reduction in execution time demonstrates the effectiveness of the optimization technique, as it reduces the query processing time by approximately \textit{39.47\%}, leading to faster and more efficient database operations.

\item \textbf{Impact of MV on CPU and elapsed time:} The \hyperref[tab:performance]{\textit{Table}~\ref*{tab:performance}} shows the execution metrics for three queries, highlighting significant improvements when using MVs. Particularly is the \textit{MonthlyClaimsByProvider} where CPU and elapsed times were reduced by factors 47x and 38x, respectively. The \textit{"TotalTreatmentCostByProvider"} showed modest benefits (1.1× and 1.6×), while the  \textit{"TotalClaimsByPatient"} demonstrated more notable gains, with execution times improved by approximately 6.3×. The results confirm that materialized views can substantially enhance query performance, especially for complex data aggregations and frequent report generation.
\input{Table/updated}
\clearpage

%\input{Table/cpu_performance}


%\item \textbf{Bar Chart Comparison:} As shown in the \hyperref[fig:execution-plan]{barchart}, the execution time demonstrates the optimization achieved by using materialized views. Direct select aggregation is the least efficient as it involves computing aggregation directly from the raw data during query execution, which is resource-intensive and time-consuming. On the other hand, a materialized view is the fastest one. Although the choice of method depends on the trade-off between query speed, storage requirements, and maintenance.



%\begin{figure}[H]
%\centering
%\includegraphics[width=0.8\textwidth]{Figure/Bar_chart.png} % Replace with your image file name
%\caption{Comparison of query execution time} % Caption for the screenshot
%\label{fig:execution-plan} % Label for referencing
%\end{figure}


\end{itemize} \vspace{.4cm}

\item \textbf{CPU performance analysis:}

The following \hyperref[fig:cpu_usage]{\textit{bar chart}} illustrates the average CPU usage for query execution before and after materialized views (MVs) are implemented. The x-axis is used to represent two conditions: \textit{Before} MVs (without materialized views) and \textit{After} MVs (with materialized views). The y-axis is used to represent the average CPU usage as a percentage. As it is evident from the graph, the CPU utilization average went down significantly from \textbf{85\%} (before MVs) to \textbf{30\%} (after MVs), showcasing the effectiveness of materialized views in reducing CPU burden in query processing. The reduction can be accounted for due to precomputation and caching of query output, which reduces real-time computation and subsequently CPU consumption.

\input{Table/cpu_performance}




 \textbf{Data will be updated once the final implementation is done}.

